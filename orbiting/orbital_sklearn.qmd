---
title: "Scikit Learn + Orbital"
subtitle: Simple use case example
author: Edgar Ruiz - Posit
date: 2025-05-20
format: html
editor: visual
execute:
  eval: false
---

## Use case

Using loan data, we want to use a model that estimates an appropriate interest rate, and then use that model to find out if the interest rate for a given loan may have been too high.

## Approach

*"Fit small, predict big"*

To make it as close to a 'real-life' scenario, we will download a sample of the table into our Python session, fit a model using a Scikit Learn pipeline, and then use Orbital to translate the steps and estimates into a SQL statement. Finally, we will use that SQL statement as the base to compare the current interest against the prediction, and download the loans that had a large difference. See @fig-diagram.

::: {#fig-diagram}
```{mermaid}
flowchart LR
  A[1-Full Table] --Download--> B(2-Sample) 
  B--Scikit Learn fit-->C(3-Model)
  C--Orbital parse-->D(4-SQL)
  D--Predict-->A
```

Diagram of the approach used for this use case
:::

## Download sample

1.  Load necessary libraries. Make sure to have `databricks-sql-connector` installed in your environment, that is the source of `databricks`.

    ```{python}
    from dotenv import load_dotenv
    from databricks import sql
    import pandas as pd
    import os
    ```

2.  Load the credentials to be used via their respective environment variables.

    ```{python}
    load_dotenv()
    host = os.getenv("DATABRICKS_HOST")
    token = os.getenv("DATABRICKS_TOKEN")
    ```

3.  For simplicity's sake, the table's catalog, schema and HTTP path into variables.

    ```{python}
    schema = "end-to-end"
    catalog = "sol_eng_demo_nickp"
    http_path = "/sql/1.0/warehouses/b71952ebceb705ce"
    ```

4.  Establish the database connection using the defined variables 

    ```{python}
    con = sql.connect(host, http_path, token, catalog = catalog, schema = schema)
    ```

5.  Using `TABLESAMPLE`, download 100 rows. `REPEATABLE` is used for purposes
of reproducibility.

    ```{python}
    con_cursor = con.cursor()
    con_cursor.execute(
      "select * from loans_full_schema TABLESAMPLE (100 ROWS) REPEATABLE (999);"
      )
    ```

6.  Iterate through the field descriptions to extract their respective names

    ```{python}
    col_names = [desc[0] for desc in con_cursor.description]
    ```

7.  Convert the downloaded data into Pandas

    ```{python}
    res = con_cursor.fetchall()
    full_df = pd.DataFrame(res, columns=col_names)
    ```


## Fit locally

1.  Load the appropiate Scikit Learn modules
    
    ```{python}
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import StandardScaler
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    ```

2.  Select the fields that will be used for predictors, and add them to a list 
called `pred_names`. 

    ```{python}
    pred_names = ["annual_income", "total_credit_lines", "loan_amount",  "term"]
    ```

3.  Subset the data into a new variable (`predictors`)

    ```{python}
    predictors = full_df[pred_names]
    ```
    
4.  Pull the interest rate field from the data into a new variable (`outcome`)
    
    ```{python}
    outcome = full_df["interest_rate"]
    ```

5.  Split the rows into train and test

    ```{python}
    pred_train, pred_test, out_train, out_test = train_test_split(
        predictors, outcome, test_size=20, random_state=999
    )
    ```

6.  Create the pipeline. Use `pre_names` to define the fields to run the scaler
    against
    
    ```{python}
    pipeline = Pipeline(
        [("preprocess", 
          ColumnTransformer(
            [("scaler", StandardScaler(with_std=False), pred_names)],
            remainder="passthrough")
            ),
        ("linear_regression", LinearRegression())]
    )
    ```

7.  Fit the pipeline

    ```{python}
    pipeline.fit(pred_train, out_train)
    ```


## Convert to SQL using Orbital

```{python}

import orbitalml
import orbitalml.types

orbital_pipeline = orbitalml.parse_pipeline(pipeline, features={
    "annual_income": orbitalml.types.DoubleColumnType(),
    "total_credit_lines": orbitalml.types.DoubleColumnType(),
    "loan_amount": orbitalml.types.DoubleColumnType(),    
    "term": orbitalml.types.DoubleColumnType(),
    "loan_id": orbitalml.types.Int32ColumnType(),
    "emp_title": orbitalml.types.StringColumnType(),
    "loan_amount": orbitalml.types.DoubleColumnType(),
    "balance": orbitalml.types.DoubleColumnType(),
    "application_type": orbitalml.types.StringColumnType(),
    "interest_rate": orbitalml.types.DoubleColumnType()
})

orbital_pipeline
```

```{python}

pred_sql = orbitalml.export_sql(
    table_name="loans_full_schema", 
    pipeline=orbital_pipeline, 
    projection= orbitalml.ResultsProjection(["loan_amount", "term"]),
    dialect="databricks"
    )

pred_sql
```

## Predict against full table

```{python}

con_cursor = con.cursor()
con_cursor.execute(f"select * from ({pred_sql}) where interest_rate - variable > 15 and variable > 0")
pred_cols = [desc[0] for desc in con_cursor.description]
res = con_cursor.fetchall()
pred_df = pd.DataFrame(res, columns=pred_cols)
pred_df
```
