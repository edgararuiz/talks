---
title: Databricks + Scikit Learn + Orbital
subtitle: Simple use case example
author: Edgar Ruiz - Posit
date: 2025-05-20
format: html
editor: visual
execute:
  eval: false
toc: true  
toc-expand: true
---

```{r}
#| include: false
library(tidymodels)
library(tidyverse)

options("odbc.no_config_override"=FALSE)
```


## Use case

Using loan data, we want to use a model that estimates an appropriate interest 
rate, and then use that model to find out if the interest rate for a given loan
may have been too high. The loan data is in a table located in the Databricks 
Unity Catalog. The ultimate objective of the project, is to have it check on 
a daily basis to see what loans may an issue. 

## Approach

*"Fit small, predict big"*

To make it as close to a 'real-life' scenario, we will download a sample of the 
table into our Python session, fit a model using a Scikit Learn pipeline, and
then use Orbital to translate the steps and estimates into a SQL statement. 
Finally, we will use that SQL statement as the base to compare the current 
interest against the prediction, and download the loans that had a large 
difference. Thanks to the integrated environment in Databricks, the resulting
SQL statement will be saved in the Databricks Workspace, and used to run
on a schedule via a [Databricks Job](https://docs.databricks.com/aws/en/jobs/).


## Download sample

```{r}
library(DBI)

con <- dbConnect(
  drv = odbc::databricks(), 
  httpPath = "/sql/1.0/warehouses/b71952ebceb705ce"
  )
```


```{r}
schema <- "end-to-end"
catalog <- "sol_eng_demo_nickp"
table <- "loans_full_schema"
```


```{r}
library(glue)

sample_sql <- glue_sql(
  "SELECT * ", 
  "FROM ",
  "{`catalog`}.{`schema`}.{`table`}",
  "TABLESAMPLE (100 ROWS) REPEATABLE (999)",
  .con = con
  )

sample_sql
```


```{r}
sample_lending <- dbGetQuery(
  conn = con, 
  statement = sample_sql
  )
```

```{r}
head(sample_lending)
```


## Fit locally

```{r}
set.seed(999)
library(tidymodels)

sample_lending <- sample_lending |> 
  mutate(
    total_credit_lines = as.double(total_credit_lines),
    loan_amount = as.double(loan_amount),
    term = as.double(term)
    )

split_lending <- initial_split(sample_lending)

lending_training <- training(split_lending)

train_lend <- lending_training[, c("annual_income", "total_credit_lines", "loan_amount",  "term", "interest_rate")]
rec_lending <- recipe(
  interest_rate ~ annual_income + total_credit_lines + loan_amount + term, 
  data = lending_training
  ) |> 
  step_normalize(all_numeric_predictors())


lm_spec <- linear_reg()

wf_spec <- workflow(rec_lending, lm_spec)

wf_fit <- fit(wf_spec, lending_training)

wf_fit
```




## Convert to SQL using Orbital

```{r}
library(orbital)

lending_orbital <-  orbital(wf_fit)

lending_orbital
```

```{r}
lending_sql <- orbital_sql(lending_orbital, con)

lending_sql
```

```{r}
	
lending_sql |> 
  imap(\(x,y) glue("{x} AS {y}")) |> 
  glue_sql_collapse(sep = ", ")
    
```

