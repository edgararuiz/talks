---
format: 
  revealjs:
    smaller: true
    transition: fade
    background-transition: fade
    theme: [default, theme.scss]
    menu: false
execute: 
  echo: false
---

# Databricks with R {background-image="assets/title-slide-white.png"}

Edgar Ruiz \@ Posit

[linkedin.com/in/edgararuiz](https://www.linkedin.com/in/edgararuiz/)

## Spark Connect {background-image="assets/slide-frame.png"}

-   Introduced a decoupled client-server architecture. It enables remote connectivity to Spark clusters.

-   **Allows R users to interact with a cluster** from their preferred environment, laptop or otherwise.

-   [Databricks Connect](https://docs.databricks.com/dev-tools/databricks-connect.html), 
    is based on **Spark Connect** architecture. Available in DBR version 13+


## Spark Connect {background-image="assets/slide-frame.png"}

-   Uses of a *remote procedure call* framework, named **gRPC**.

-   Uses **Torch** for the ML capabilities.

-   `PySpark` offers the best integration with Connect.

```{mermaid}
flowchart LR
  subgraph lp[User's machine]
    ps[PySpark]
    g1[gRPC]
  end
  sp[Spark]
  
  g1 <-. Network .-> sp
  ps --> g1
  
  style ps  fill:#eff,stroke:#666
  style lp  fill:#fff,stroke:#666
  style sp  fill:#f4c430,stroke:#666
  style g1  fill:#447099,stroke:#666,color:#fff
```

## Integrating R {background-image="assets/slide-frame.png"}

-   `sparklyr` integrates to PySpark via `reticulate` 

-   Extends the functionality, and user experience: 
    - `dplyr` back-end
    - `DBI` back-end 
    - RStudio's *Connections pane* integration.

## Databricks Connect (DBR 13+) {background-image="assets/slide-frame.png"}

`sparkly` 1.8.3 now supports Databricks Connect "v2":

``` r
library(sparklyr)

sc <- spark_connect(
  master     = "", # Your org's address
  cluster_id = "", # Your cluster's ID
  token      = "", # Your personal token
  method     = "databricks_connect"
 )
```

## Databricks Connect (DBR 13+) {background-image="assets/slide-frame.png"}

`sparklyr` uses environment variables, if provided:

  -   `DATABRICKS_HOST` - Your org's address
  
  -   `DATABRICKS_CLUSTER_ID` - Your cluster's ID
  
  -   `DATABRICKS_TOKEN` - Your personal token

Simplifies, and secures connection code:

``` r
sc <- spark_connect(
  method = "databricks_connect"
 )
```

## Databricks Catalog Explorer {background-image="assets/slide-frame.png"}

![](assets/catalog-explorer.png)

## Connection Pane {background-image="assets/slide-frame.png"}

![](assets/rstudio-connection.png){width="507"}

## Preview top 1000 rows {background-image="assets/slide-frame.png"}

![](assets/preview.png)
