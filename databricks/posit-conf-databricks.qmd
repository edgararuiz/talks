---
format: 
  revealjs:
    smaller: true
    transition: fade
    background-transition: fade
    theme: [default, theme.scss]
    menu: false
execute: 
  echo: false
---

# Databricks with R {background-image="assets/title-slide-white.png"}

Edgar Ruiz \@ Posit

[linkedin.com/in/edgararuiz](https://www.linkedin.com/in/edgararuiz/)

## Spark Connect {background-image="assets/slide-frame.png"}

-   Introduced a decoupled client-server architecture

-   It enables remote connectivity to Spark clusters.

-   **Allows R users to interact with a cluster** from their preferred environment, laptop or otherwise.

-   [Databricks Connect](https://docs.databricks.com/dev-tools/databricks-connect.html), is based on **Spark Connect** architecture. Available in DBR version 13+

```{mermaid}
%%| fig-height: '500px'

flowchart LR
  lp[User's machine]
  sp[Spark]
  
  lp <-. Network .-> sp
  
  style lp  fill:#fff,stroke:#666
  style sp  fill:#f4c430,stroke:#666
```

## Spark Connect {background-image="assets/slide-frame.png"}

-   Uses of a *remote procedure call* framework, named **gRPC**.

-   Uses **Torch** for the ML capabilities.

-   `PySpark` offers the best integration with Connect.

```{mermaid}
flowchart LR
  subgraph lp[User's machine]
    ps[PySpark]
    g1[gRPC]
  end
  sp[Spark]
  
  g1 <-. Network .-> sp
  ps --> g1
  
  style ps  fill:#eff,stroke:#666
  style lp  fill:#fff,stroke:#666
  style sp  fill:#f4c430,stroke:#666
  style g1  fill:#447099,stroke:#666,color:#fff
```

## Integrating R {background-image="assets/slide-frame.png"}

-   `sparklyr` integrates with PySpark, via `reticulate`

-   `sparklyr` extends the functionality, and user experience:

    -   `dplyr` back-end
    -   `DBI` back-end
    -   RStudio's *Connections pane* integration.

```{mermaid}
flowchart LR
  subgraph lp[User's machine]
    sr[sparklyr]
    rt[reticulate]
    ps[PySpark]
    g1[gRPC]
  end
  sp[Spark]
  
  sr --> rt
  rt --> ps
  g1 <-. Network .-> sp
  ps --> g1
  
  style sr  fill:#d0efb1,stroke:#666
  style rt  fill:#d0efb1,stroke:#666
  style ps  fill:#eff,stroke:#666
  style lp  fill:#fff,stroke:#666
  style sp  fill:#f4c430,stroke:#666
  style g1  fill:#447099,stroke:#666,color:#fff
```

:::{.incremental}
- -----------   No need to install Java in my machine!!! ðŸŽ‰  -------------
:::

## Databricks Connect (DBR 13+) {background-image="assets/slide-frame.png"}

`sparkly` 1.8.3 now supports Databricks Connect "v2":

``` r
library(sparklyr)

sc <- spark_connect(
  master     = "", # Your org's address
  cluster_id = "", # Your cluster's ID
  token      = "", # Your personal token
  method     = "databricks_connect"
 )
```

## Databricks Connect (DBR 13+) {background-image="assets/slide-frame.png"}

`sparklyr` uses environment variables, if provided:

-   `DATABRICKS_HOST` - Your org's address

-   `DATABRICKS_CLUSTER_ID` - Your cluster's ID

-   `DATABRICKS_TOKEN` - Your personal token

Simplifies, and secures connection code:

``` r
sc <- spark_connect(
  method = "databricks_connect"
 )
```

## Databricks Catalog Explorer {background-image="assets/slide-frame.png"}

![](assets/catalog-explorer.png)

## Connection Pane {background-image="assets/slide-frame.png"}

![](assets/rstudio-connection.png){width="507"}

## Preview top 1000 rows {background-image="assets/slide-frame.png"}

![](assets/preview.png)
